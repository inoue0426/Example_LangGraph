{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d17a12a4-3534-495f-a7f9-3c36bd46059e",
   "metadata": {},
   "source": [
    "# https://langchain-ai.github.io/langgraph/tutorials/rag/langgraph_crag_local/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91e22120-3d72-4cc3-9b25-e6ae0ceb7a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"llama3\"\n",
    "model_tested = \"llama3-8b\"\n",
    "metadata = f\"CRAG, {model_tested}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d1cb095-3dcc-4ce3-87c1-3da0efcf252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_nomic.embeddings import NomicEmbeddings  # local\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "from IPython.display import Image, display\n",
    "from langchain.schema import Document\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "import uuid\n",
    "from langsmith import Client\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langsmith.schemas import Example, Run\n",
    "from langsmith.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8da55624-20c6-4c59-b949-2b41d109aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of URLs to load documents from\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]\n",
    "\n",
    "# Load documents from the URLs\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# Initialize a text splitter with specified chunk size and overlap\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "\n",
    "# Split the documents into chunks\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Embedding\n",
    "embedding=NomicEmbeddings(\n",
    "    model=\"nomic-embed-text-v1.5\",\n",
    "    inference_mode=\"local\",\n",
    ")\n",
    "\n",
    "# Add the document chunks to the \"vector store\"\n",
    "vectorstore = SKLearnVectorStore.from_documents(\n",
    "    documents=doc_splits,\n",
    "    embedding=embedding,\n",
    ")\n",
    "retriever = vectorstore.as_retriever(k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6760aca6-952e-4067-8e5d-3092622eec3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 1}\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a teacher grading a quiz. You will be given: \n",
    "    1/ a QUESTION\n",
    "    2/ A FACT provided by the student\n",
    "    \n",
    "    You are grading RELEVANCE RECALL:\n",
    "    A score of 1 means that ANY of the statements in the FACT are relevant to the QUESTION. \n",
    "    A score of 0 means that NONE of the statements in the FACT are relevant to the QUESTION. \n",
    "    1 is the highest (best) score. 0 is the lowest score you can give. \n",
    "    \n",
    "    Explain your reasoning in a step-by-step manner. Ensure your reasoning and conclusion are correct. \n",
    "    \n",
    "    Avoid simply stating the correct answer at the outset.\n",
    "    \n",
    "    Question: {question} \\n\n",
    "    Fact: \\n\\n {documents} \\n\\n\n",
    "    \n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explanation.\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"agent memory\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"documents\": doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c8867f-80ce-402f-9b70-22ca9b065b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to the documents, agent memory refers to the long-term memory module that records a comprehensive list of agents' experience in natural language. This allows the agent to retain and recall information over extended periods.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks. \n",
    "    \n",
    "    Use the following documents to answer the question. \n",
    "    \n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    \n",
    "    Use three sentences maximum and keep the answer concise:\n",
    "    Question: {question} \n",
    "    Documents: {documents} \n",
    "    Answer: \n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"documents\"],\n",
    ")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({\"documents\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee19cbaa-18f9-438d-97a3-b513d27456e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccedc637-d4e4-4c32-af16-bf2b8126226b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        question: question\n",
    "        generation: LLM generation\n",
    "        search: whether to add search\n",
    "        documents: list of documents\n",
    "    \"\"\"\n",
    "\n",
    "    question: str\n",
    "    generation: str\n",
    "    search: str\n",
    "    documents: List[str]\n",
    "    steps: List[str]\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"retrieve_documents\")\n",
    "    return {\"documents\": documents, \"question\": question, \"steps\": steps}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"documents\": documents, \"question\": question})\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"generate_answer\")\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "        \"question\": question,\n",
    "        \"generation\": generation,\n",
    "        \"steps\": steps,\n",
    "    }\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with only filtered relevant documents\n",
    "    \"\"\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"grade_document_retrieval\")\n",
    "    filtered_docs = []\n",
    "    search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke(\n",
    "            {\"question\": question, \"documents\": d.page_content}\n",
    "        )\n",
    "        grade = score[\"score\"]\n",
    "        if grade == \"yes\":\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            search = \"Yes\"\n",
    "            continue\n",
    "    return {\n",
    "        \"documents\": filtered_docs,\n",
    "        \"question\": question,\n",
    "        \"search\": search,\n",
    "        \"steps\": steps,\n",
    "    }\n",
    "\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based on the re-phrased question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "    steps = state[\"steps\"]\n",
    "    steps.append(\"web_search\")\n",
    "    web_results = web_search_tool.invoke({\"query\": question})\n",
    "    documents.extend(\n",
    "        [\n",
    "            Document(page_content=d[\"content\"], metadata={\"url\": d[\"url\"]})\n",
    "            for d in web_results\n",
    "        ]\n",
    "    )\n",
    "    return {\"documents\": documents, \"question\": question, \"steps\": steps}\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or re-generate a question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "    search = state[\"search\"]\n",
    "    if search == \"Yes\":\n",
    "        return \"search\"\n",
    "    else:\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "# Graph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"retrieve\", retrieve)  # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents)  # grade documents\n",
    "workflow.add_node(\"generate\", generate)  # generatae\n",
    "workflow.add_node(\"web_search\", web_search)  # web search\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"search\": \"web_search\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "workflow.add_edge(\"generate\", END)\n",
    "\n",
    "custom_graph = workflow.compile()\n",
    "\n",
    "display(Image(custom_graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cea2c31-49a9-4952-8d85-aa936a42053a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': \"According to the documents, there are two main categories of agent memory:\\n\\n* Short-term Memory: This allows agents to utilize short-term memory of large language models to operate on original problems.\\n* Long-term Memory (LTM): This has three subcategories:\\n\\t+ Procedural memory: represents the agent's procedures for thinking, acting, and decision-making.\\n\\nNote that there is no mention of episodic or semantic memory in these documents.\",\n",
       " 'steps': ['retrieve_documents',\n",
       "  'grade_document_retrieval',\n",
       "  'web_search',\n",
       "  'generate_answer']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_custom_agent_local_answer(example: dict):\n",
    "    config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "    state_dict = custom_graph.invoke(\n",
    "        {\"question\": example[\"input\"], \"steps\": []}, config\n",
    "    )\n",
    "    return {\"response\": state_dict[\"generation\"], \"steps\": state_dict[\"steps\"]}\n",
    "\n",
    "\n",
    "example = {\"input\": \"What are the types of agent memory?\"}\n",
    "response = predict_custom_agent_local_answer(example)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c895743d-f69f-478f-b0c5-1999d8aa21c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client()\n",
    "\n",
    "# Create a dataset\n",
    "examples = [\n",
    "    (\n",
    "        \"How does the ReAct agent use self-reflection? \",\n",
    "        \"ReAct integrates reasoning and acting, performing actions - such tools like Wikipedia search API - and then observing / reasoning about the tool outputs.\",\n",
    "    ),\n",
    "    (\n",
    "        \"What are the types of biases that can arise with few-shot prompting?\",\n",
    "        \"The biases that can arise with few-shot prompting include (1) Majority label bias, (2) Recency bias, and (3) Common token bias.\",\n",
    "    ),\n",
    "    (\n",
    "        \"What are five types of adversarial attacks?\",\n",
    "        \"Five types of adversarial attacks are (1) Token manipulation, (2) Gradient based attack, (3) Jailbreak prompting, (4) Human red-teaming, (5) Model red-teaming.\",\n",
    "    ),\n",
    "    (\n",
    "        \"Who did the Chicago Bears draft first in the 2024 NFL draft”?\",\n",
    "        \"The Chicago Bears drafted Caleb Williams first in the 2024 NFL draft.\",\n",
    "    ),\n",
    "    (\"Who won the 2024 NBA finals?\", \"The Boston Celtics on the 2024 NBA finals\"),\n",
    "]\n",
    "\n",
    "# Save it\n",
    "dataset_name = \"Corrective RAG Agent Testing\"\n",
    "if not client.has_dataset(dataset_name=dataset_name):\n",
    "    dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "    inputs, outputs = zip(\n",
    "        *[({\"input\": text}, {\"output\": label}) for text, label in examples]\n",
    "    )\n",
    "    client.create_examples(inputs=inputs, outputs=outputs, dataset_id=dataset.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6519259f-e287-4aba-b27d-b15778d34344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade prompt\n",
    "grade_prompt_answer_accuracy = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
    "\n",
    "\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    A simple evaluator for RAG answer accuracy\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the question, the ground truth reference answer, RAG chain answer prediction\n",
    "    input_question = example.inputs[\"input\"]\n",
    "    reference = example.outputs[\"output\"]\n",
    "    prediction = run.outputs[\"response\"]\n",
    "\n",
    "    # Define an LLM grader\n",
    "    llm = ChatOllama(model=local_llm, temperature=0)\n",
    "    answer_grader = grade_prompt_answer_accuracy | llm\n",
    "\n",
    "    # Run evaluator\n",
    "    score = answer_grader.invoke(\n",
    "        {\n",
    "            \"question\": input_question,\n",
    "            \"correct_answer\": reference,\n",
    "            \"student_answer\": prediction,\n",
    "        }\n",
    "    )\n",
    "    score = score[\"Score\"]\n",
    "    return {\"key\": \"answer_v_reference_score\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c833bcdb-ad82-48cf-a552-f133447be80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reasoning traces that we expect the agents to take\n",
    "expected_trajectory_1 = [\n",
    "    \"retrieve_documents\",\n",
    "    \"grade_document_retrieval\",\n",
    "    \"web_search\",\n",
    "    \"generate_answer\",\n",
    "]\n",
    "expected_trajectory_2 = [\n",
    "    \"retrieve_documents\",\n",
    "    \"grade_document_retrieval\",\n",
    "    \"generate_answer\",\n",
    "]\n",
    "\n",
    "\n",
    "def find_tool_calls_react(messages):\n",
    "    \"\"\"\n",
    "    Find all tool calls in the messages returned\n",
    "    \"\"\"\n",
    "    tool_calls = [tc['name'] for m in messages['messages'] for tc in getattr(m, 'tool_calls', [])]\n",
    "    return tool_calls\n",
    "\n",
    "\n",
    "def check_trajectory_react(root_run: Run, example: Example) -> dict:\n",
    "    \"\"\"\n",
    "    Check if all expected tools are called in exact order and without any additional tool calls.\n",
    "    \"\"\"\n",
    "    messages = root_run.outputs[\"messages\"]\n",
    "    tool_calls = find_tool_calls_react(messages)\n",
    "    print(f\"Tool calls ReAct agent: {tool_calls}\")\n",
    "    if tool_calls == expected_trajectory_1 or tool_calls == expected_trajectory_2:\n",
    "        score = 1\n",
    "    else:\n",
    "        score = 0\n",
    "\n",
    "    return {\"score\": int(score), \"key\": \"tool_calls_in_exact_order\"}\n",
    "\n",
    "\n",
    "def check_trajectory_custom(root_run: Run, example: Example) -> dict:\n",
    "    \"\"\"\n",
    "    Check if all expected tools are called in exact order and without any additional tool calls.\n",
    "    \"\"\"\n",
    "    tool_calls = root_run.outputs[\"steps\"]\n",
    "    print(f\"Tool calls custom agent: {tool_calls}\")\n",
    "    if tool_calls == expected_trajectory_1 or tool_calls == expected_trajectory_2:\n",
    "        score = 1\n",
    "    else:\n",
    "        score = 0\n",
    "\n",
    "    return {\"score\": int(score), \"key\": \"tool_calls_in_exact_order\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cd2904d2-551b-4df3-a7a2-121344a6651d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'custom-agent-llama3-8b-answer-and-tool-use-38ceb638' at:\n",
      "https://smith.langchain.com/o/fb28be30-d3ba-59e8-9a35-172eba072515/datasets/20eab020-fb71-4c59-9e6d-7c9ffd828855/compare?selectedSessions=b38b79ff-c859-461a-bb19-d2a3ee1477d9\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fdbd22fca1a443196c6acb342c0bd8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run ea53f45b-e585-46f4-95a2-53090b27b4e3: NotImplementedError()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/s4/6xgylm7x3yzgfsk6sbvk_7_c0000gn/T/ipykernel_27190/1101936708.py\", line 17, in answer_evaluator\n",
      "    answer_grader = grade_prompt_answer_accuracy | llm\n",
      "                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langchain_core/prompts/structured.py\", line 117, in __or__\n",
      "    return self.pipe(other)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langchain_core/prompts/structured.py\", line 149, in pipe\n",
      "    others[0].with_structured_output(\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1250, in with_structured_output\n",
      "    llm = self.bind_tools([schema], tool_choice=\"any\")\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1127, in bind_tools\n",
      "    raise NotImplementedError()\n",
      "NotImplementedError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool calls custom agent: ['retrieve_documents', 'grade_document_retrieval', 'web_search', 'generate_answer']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run f5ea38f5-a8ca-47a1-bb58-b896f25a40ed: NotImplementedError()\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py\", line 1345, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/evaluator.py\", line 327, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/run_helpers.py\", line 646, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/run_helpers.py\", line 643, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/s4/6xgylm7x3yzgfsk6sbvk_7_c0000gn/T/ipykernel_27190/1101936708.py\", line 17, in answer_evaluator\n",
      "    answer_grader = grade_prompt_answer_accuracy | llm\n",
      "                    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langchain_core/prompts/structured.py\", line 117, in __or__\n",
      "    return self.pipe(other)\n",
      "           ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langchain_core/prompts/structured.py\", line 149, in pipe\n",
      "    others[0].with_structured_output(\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1250, in with_structured_output\n",
      "    llm = self.bind_tools([schema], tool_choice=\"any\")\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yoshitakainoue/miniconda3/envs/multi/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py\", line 1127, in bind_tools\n",
      "    raise NotImplementedError()\n",
      "NotImplementedError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool calls custom agent: ['retrieve_documents', 'grade_document_retrieval', 'web_search', 'generate_answer']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:1311\u001b[0m, in \u001b[0;36m_ExperimentManager._predict\u001b[0;34m(self, target, max_concurrency)\u001b[0m\n\u001b[1;32m   1300\u001b[0m futures \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   1301\u001b[0m     executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m   1302\u001b[0m         _forward,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexamples\n\u001b[1;32m   1310\u001b[0m ]\n\u001b[0;32m-> 1311\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/concurrent/futures/_base.py:243\u001b[0m, in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m(\n\u001b[1;32m    240\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m (of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) futures unfinished\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\n\u001b[1;32m    241\u001b[0m                 \u001b[38;5;28mlen\u001b[39m(pending), total_futures))\n\u001b[0;32m--> 243\u001b[0m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m waiter\u001b[38;5;241m.\u001b[39mlock:\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/threading.py:629\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 629\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/threading.py:327\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 327\u001b[0m     \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m experiment_prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcustom-agent-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_tested\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m experiment_results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_custom_agent_local_answer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43manswer_evaluator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_trajectory_custom\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-answer-and-tool-use\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Use when running locally\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mversion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:262\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mand\u001b[39;00m experiment_prefix:\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected at most one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexperiment_prefix\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m but both were provided. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot: experiment=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, experiment_prefix=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m     )\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:901\u001b[0m, in \u001b[0;36m_evaluate\u001b[0;34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment)\u001b[0m\n\u001b[1;32m    899\u001b[0m     manager \u001b[38;5;241m=\u001b[39m manager\u001b[38;5;241m.\u001b[39mwith_summary_evaluators(summary_evaluators)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# Start consuming the results.\u001b[39;00m\n\u001b[0;32m--> 901\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mExperimentResults\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mblocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:402\u001b[0m, in \u001b[0;36mExperimentResults.__init__\u001b[0;34m(self, experiment_manager, blocking)\u001b[0m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_thread \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:427\u001b[0m, in \u001b[0;36mExperimentResults._process_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    425\u001b[0m tqdm \u001b[38;5;241m=\u001b[39m _load_tqdm()\n\u001b[1;32m    426\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39mget_results()\n\u001b[0;32m--> 427\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_results\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:1263\u001b[0m, in \u001b[0;36m_ExperimentManager.get_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_results\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[ExperimentResultRow]:\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the traces, evaluation results, and associated examples.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1263\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_results\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mExperimentResultRow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:1236\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;66;03m# Split the generator into three so the manager\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;66;03m# can consume each value individually.\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m r1, r2, r3 \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mtee(experiment_results, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ExperimentManager(\n\u001b[1;32m   1232\u001b[0m     (result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m r1),\n\u001b[1;32m   1233\u001b[0m     experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment,\n\u001b[1;32m   1234\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata,\n\u001b[1;32m   1235\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient,\n\u001b[0;32m-> 1236\u001b[0m     runs\u001b[38;5;241m=\u001b[39m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr2\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1237\u001b[0m     evaluation_results\u001b[38;5;241m=\u001b[39m(result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_results\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m r3),\n\u001b[1;32m   1238\u001b[0m     summary_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary_results,\n\u001b[1;32m   1239\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:1391\u001b[0m, in \u001b[0;36m_ExperimentManager._score\u001b[0;34m(self, evaluators, max_concurrency)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1390\u001b[0m     futures \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m-> 1391\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcurrent_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1393\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1394\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[1;32m   1401\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Since prediction may be slow, yield (with a timeout) to\u001b[39;49;00m\n\u001b[1;32m   1402\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# allow for early results to be emitted.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:1263\u001b[0m, in \u001b[0;36m_ExperimentManager.get_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_results\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[ExperimentResultRow]:\n\u001b[1;32m   1262\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the traces, evaluation results, and associated examples.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1263\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1264\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_results\u001b[49m\n\u001b[1;32m   1265\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1266\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mExperimentResultRow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1267\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1268\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1269\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevaluation_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluation_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1270\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:1207\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1198\u001b[0m _experiment_results \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[1;32m   1199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predict, target, max_concurrency\u001b[38;5;241m=\u001b[39mmax_concurrency\n\u001b[1;32m   1200\u001b[0m )\n\u001b[1;32m   1201\u001b[0m r1, r2 \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mtee(_experiment_results, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ExperimentManager(\n\u001b[1;32m   1203\u001b[0m     (pred[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m pred \u001b[38;5;129;01min\u001b[39;00m r1),\n\u001b[1;32m   1204\u001b[0m     experiment\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_experiment,\n\u001b[1;32m   1205\u001b[0m     metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata,\n\u001b[1;32m   1206\u001b[0m     client\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient,\n\u001b[0;32m-> 1207\u001b[0m     runs\u001b[38;5;241m=\u001b[39m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr2\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;66;03m# TODO: Can't do multiple prediction rounds rn.\u001b[39;00m\n\u001b[1;32m   1209\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/site-packages/langsmith/evaluation/_runner.py:1299\u001b[0m, in \u001b[0;36m_ExperimentManager._predict\u001b[0;34m(self, target, max_concurrency)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _forward(\n\u001b[1;32m   1295\u001b[0m             fn, example, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperiment_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\n\u001b[1;32m   1296\u001b[0m         )\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1299\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mls_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mContextThreadPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_forward\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1309\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexamples\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfuture\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_completed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/concurrent/futures/_base.py:647\u001b[0m, in \u001b[0;36mExecutor.__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/concurrent/futures/thread.py:235\u001b[0m, in \u001b[0;36mThreadPoolExecutor.shutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads:\n\u001b[0;32m--> 235\u001b[0m         \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/threading.py:1119\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/multi/lib/python3.11/threading.py:1139\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1140\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment_prefix = f\"custom-agent-{model_tested}\"\n",
    "experiment_results = evaluate(\n",
    "    predict_custom_agent_local_answer,\n",
    "    data=dataset_name,\n",
    "    evaluators=[answer_evaluator, check_trajectory_custom],\n",
    "    experiment_prefix=experiment_prefix + \"-answer-and-tool-use\",\n",
    "    num_repetitions=3,\n",
    "    max_concurrency=1,  # Use when running locally\n",
    "    metadata={\"version\": metadata},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d933a4-c591-43f1-bff0-c65de1be339f",
   "metadata": {},
   "source": [
    "# Not implementation error was occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3508cd2-e401-4545-9e31-3f0d5b21967d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi",
   "language": "python",
   "name": "multi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
